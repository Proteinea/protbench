{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### To Extract Embeddings from any model you would need the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hazem/pt/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from protbench.embedder import ComputeEmbeddingsWrapper\n",
    "from protbench.embedder import SaveDirectories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SaveDirectories is a simple dataclass to store where to store your embeddings and to specify the parent directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SaveDirectories(parent_dir='/root/.cache', train_dir='train_embeddings', validation_dir='validation_embeddings', test_dir='test_embeddings')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_dirs = SaveDirectories()\n",
    "save_dirs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = None # Your model.\n",
    "tokenizer = None # your tokenizer.\n",
    "\n",
    "# Your tokenizer options (e.g.\n",
    "# tokenizer_options = {\"return_tensors\": \"pt\", \"add_special_tokens\": True, ...}).\n",
    "tokenizer_options = {}\n",
    "\n",
    "# ComputeEmbeddingsWrapper expects a torch.Tensor as an output,\n",
    "# if you are using Huggingface model or if your model does not\n",
    "# return torch.Tensor, you will need to specify the function\n",
    "# that will be called on the model output to return a torch.Tensor.\n",
    "post_processing_fn = lambda x: x.last_hidden_state\n",
    "\n",
    "device = \"cuda:0\"\n",
    "pad_token_id = 0\n",
    "\n",
    "# If set to True then you will need to pass\n",
    "# `SaveDirectories` instance in order to\n",
    "# save the embeddings on the disk instead\n",
    "# of storing them in memory.\n",
    "low_memory = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_embeddings = ComputeEmbeddingsWrapper(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    tokenizer_options=tokenizer_options,\n",
    "    post_processing_function=post_processing_fn,\n",
    "    device=device,\n",
    "    pad_token_id=pad_token_id,\n",
    "    low_memory=low_memory,\n",
    "    save_directories=save_dirs,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_seqs = [\"protein_sequence_1\", \"protein_sequence_2\", \"protein_sequence_3\", \"...\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_container = compute_embeddings(train_seqs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
