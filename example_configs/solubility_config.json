{
    "general": {
        "seed": 42,
        "sequence_max_length": null
    },
    "task": {
        "name": "sequence_to_class",
        "kwargs": {
            "data_file": "protbench/data/solubility/data.fasta"
        }
    },
    "pretrained_model": {
        "name": "huggingface",
        "kwargs": {
            "model_url": "ElnaggarLab/ankh-base",
            "batch_size": 1,
            "num_workers": 2
        }
    },
    "downstream_model": {
        "name": "convbert_for_binary_sequence_classification",
        "kwargs": {
            "input_dim": 768,
            "nhead": 4,
            "hidden_dim": 384,
            "num_layers": 1,
            "kernel_size": 7,
            "dropout": 0.2,
            "pooling": "max"
        }
    },
    "training_args": {
        "output_dir": "solubility",
        "run_name": "solubility",
        "num_train_epochs": 5,
        "per_device_train_batch_size": 1,
        "per_device_eval_batch_size": 1,
        "warmup_steps": 1000,
        "learning_rate": 1e-03,
        "weight_decay": 0.0,
        "logging_steps": 200,
        "do_train": true,
        "do_eval": true,
        "evaluation_strategy": "epoch",
        "gradient_accumulation_steps": 16,
        "fp16": false,
        "fp16_opt_level": "O2",
        "save_strategy": "no",
        "metric_for_best_model": "eval_accuracy",
        "greater_is_better": true,
        "report_to": "wandb"
    },
    "metrics": 
    [
        {
            "name": "accuracy"
        },
        {
            "name": "precision",
            "kwargs": {
                "average": "binary"
            }
        },
        {
            "name": "recall",
            "kwargs": {
                "average": "binary"
            }
        },
        {
            "name": "f1",
            "kwargs": {
                "average": "binary"
            }
        }
    ]
}
